name: 'vietnamese-vqa'
gpu_id: "0"
seed: 50
fp16: false
mode_test: False
multi_gpu: True
exp_dir: 'exp'
hidden_size: 768

data_params:
    train_csv_path : 'data/train.csv'
    test_csv_path : 'data/test.csv'
    label_dict_path : 'data/label_dict.json'
    image_dir : '../viq_images'

model_params:
    text_encoder:
        pretrained_model: 'vinai/phobert-base'
    image_encoder:
        model: 'vit' # ['vit', 'twin', 'van' ,'cvt']
        vit: 'ViT-B/32'
        patch_size: 32
    coattn:
        num_top_layer: 6
        vocab_size: 30522
        num_layers: 6
        num_heads: 12
        mlp_ratio: 4
        max_text_len: 40
        drop_rate: 0.1
    hidden_size: 768
    num_class: 353
    pretrained: False
    pretrained_file: ''
    drop_rate: 0.1
    network: 'baseline' # [vit-phobert-merged]
    
train_params:
    log: './log_all'
    summary_path: './'
    phase: 'train'
    input_shape: [224, 224]
    train_batch_size: 64
    infer_batch_size: 2
    initial_epoch: 0
    n_epochs: 50
    num_workers_to_cache: 8
    num_workers_from_cache: 2

optimizer:
    type: 'adam'
    args: 
        lr: 0.0001
        betas: (0.02, 0.08, 0.01)
        weight_decay: 0.01
        weight_decay_bias: 0.0

scheduler:
    type: 'multistep'
    args:
        mode: 'poly'
        warmup_length: 0
        warmup_epochs: 10
        milestones: [15, 30, 45]

inference:
    weight_path: '../weights/best_model_vit.pth'